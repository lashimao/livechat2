# Real-Time Interactive AI Makise Kurisu (Amadeus-like) 

This project implements a real-time interactive AI character, Makise Kurisu, inspired by Amadeus from Steins;Gate. It uses the Google Gemini Live API for its core AI functionalities (Speech-to-Text, Language Model, and Text-to-Speech for Kurisu's voice). The frontend is an Electron application with a Live2D model for Kurisu. 

## Architecture Overview 

*   **Frontend:** Electron application (likely using React/TypeScript based on project structure) with a Live2D model. Captures user audio/video and handles playback of AI audio and animations. 
*   **Backend:** Python server using FastAPI and `fastrtc` (for WebRTC communication with the frontend). This backend now orchestrates interactions with the Google Gemini Live API (using the Python SDK) for all AI processing. 
*   **AI:** Google Gemini Live API is used for: 
    *   User Speech-to-Text (STT). 
    *   Language Model (LLM) for generating Kurisu's responses. 
    *   Text-to-Speech (TTS) for Kurisu's voice directly from the Live API (native audio output). 
    *   Emotion cues for Live2D animation are generated by instructing Gemini (via a system prompt) to include emotion tags in its text transcriptions. 

## Setup and Installation 

**Prerequisites:** 

*   **Python:** Version 3.9 or higher recommended. 
*   **Node.js and npm:** For the frontend Electron application. 
*   **FFmpeg:** This is a crucial system-level dependency required by `pydub` (a Python audio library likely used by `fastrtc` or other backend audio utilities). 
    *   Download FFmpeg from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html). 
    *   Install it or extract the executables (`ffmpeg.exe`, `ffprobe.exe`, `ffplay.exe`) to a directory on your system. 
    *   **Important:** Add the directory containing `ffmpeg.exe` to your system's PATH environment variable. The `start_system.bat` script will warn you if it can't find FFmpeg in the PATH. 
*   **Google API Key:** You'll need a Google API key with the Gemini API enabled. 

**1. Backend Setup (Python - `service/webrtc/`)** 

   a. **Navigate to the backend directory:** 
      ```bash 
      cd service/webrtc 
      ``` 
   b. **Create and activate a Python virtual environment (recommended):** 
      ```bash 
      python -m venv venv 
      venv\Scripts\activate  # On Windows 
      # source venv/bin/activate # On macOS/Linux 
      ``` 
   c. **Install Python dependencies:** 
      ```bash 
      pip install -r requirements.txt 
      ``` 
   d. **Configure Environment Variables:** 
      *   In the `service/webrtc/` directory, copy the `.env.example` file to a new file named `.env`. 
      *   Open the `.env` file and set the following variables: 
          *   `GOOGLE_API_KEY=YOUR_GOOGLE_API_KEY_HERE` (Replace with your actual Google API Key) 
          *   `GEMINI_MODEL_NAME=gemini-1.5-flash-latest` (Or `gemini-2.0-flash-live-001`, or another Live API compatible model. Ensure it supports audio output and transcription if needed) 
          *   (Optional) `DEFAULT_USER_NAME`, `DEFAULT_SYSTEM_PROMPT` (for Kurisu's persona if you want to override the default in `prompt_utils.py`). 

**2. Frontend Setup (Electron/React - Root Directory)** 

   a. **Navigate to the project root directory.** 
   b. **Install Node.js dependencies:** 
      ```bash 
      npm install 
      ``` 

## Running the Application 

**Using the `start_system.bat` script (Windows 10):** 

1.  Ensure you have completed all the setup steps above (Python, Node.js, FFmpeg in PATH, `.env` file configured). 
2.  Navigate to the project root directory. 
3.  Double-click `start_system.bat`. 

This script will: 
*   Check for FFmpeg. 
*   Set up the Python virtual environment in `service/webrtc/` (if not already present). 
*   Install Python dependencies. 
*   Start the Python FastAPI backend server (typically on port 8001, will open in a new window or run in the background). 
*   Install Node.js dependencies (if needed). 
*   Start the Electron frontend application (using `npm run electron:dev` - this might need adjustment if your start script in `package.json` is different). 

**Manual Startup:** 

1.  **Start the Backend:** 
    *   Open a terminal, navigate to `service/webrtc/`. 
    *   Activate the virtual environment (`venv\Scripts\activate`). 
    *   Run `python server.py`. 
2.  **Start the Frontend:** 
    *   Open another terminal, navigate to the project root. 
    *   Run `npm run electron:dev` (or your project's specific start command from `package.json`). 

## Persona and Emotion 

The AI's persona as Makise Kurisu is defined by a system prompt sent to the Gemini Live API. This prompt also instructs the AI to include emotion tags (e.g., `[joy]`, `[annoyed]`) at the beginning of its text responses. The Python backend parses these tags, sends the emotion to the frontend to drive Live2D model animations, and then removes the tag from the text displayed in the chat. 

(Add any other relevant sections or remove obsolete ones based on the project's current state)
